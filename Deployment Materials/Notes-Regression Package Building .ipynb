{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Architecture\n",
    "![](images/architecture.PNG)\n",
    "\n",
    "In this section we will build the componenets related to development environment.As shown in the figure we will work on:\n",
    "1. Training the Model\n",
    "2. Building Feature Extractor\n",
    "3. Building APIs for connecting ML services to the world wide web. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Configuration\n",
    "\n",
    "This module involves the list of things required to start our ML model deployment.\n",
    "1. Github Account\n",
    "2. Git bash terminal\n",
    "3. Folking repository from [link]\n",
    "4. Creating Virtual Environmnet\n",
    "5. Installing Text Editor\n",
    "\n",
    "Below are the series of steps that can be followed to configure them.\n",
    "\n",
    "1. Create github account\n",
    "2. Install Git bash terminal from [https://git-scm.com/downloads]\n",
    "3. Go to Command propt and cofigure name and email_id\n",
    "    * git config --global user.name \"your name\"\n",
    "    * git config -- global user.email youremailaddress@x.com\n",
    "    <br>\n",
    "Check on cmd to verify config by typing:-\n",
    "    * git config user.name\n",
    "    * git config user.email\n",
    "    \n",
    "4. Folk a repository\n",
    "5. Opening Pull request to your repo instead of the original repo\n",
    "    * git remote set-url origin [link]\n",
    "6. Create a branch \n",
    "    * git checkout -b test-branch-2 \n",
    "7. Do commit\n",
    "    * git commit --allow-empty -m \"opening project\"\n",
    "8. Pull request \n",
    "    * git push origin test-branch-2\n",
    "    \n",
    "9. Creating virtual env---\n",
    "Go into the required folder\n",
    "    * python -m venv deploy\n",
    "---Check throug typing\n",
    "    * dir\n",
    "10. Activate your Virtual Environment \n",
    "    * [env_name==deploy]\\Scripts\\activate\n",
    "11. Deactivate your Virtual Environment\n",
    "    * deactivate\n",
    "12. Installing requirement files\n",
    "    * pip install -r requirements.txt\n",
    "13. Select any text editor\n",
    "    * Subime\n",
    "    * Vim\n",
    "    * Emac\n",
    "    * Pycharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our Regression Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory\n",
    "\n",
    "![](images/dir_structure.PNG)\n",
    "\n",
    "The above files can be categorized based on the task they intend to do.We can broadly divide our task in the following categories:\n",
    "\n",
    "1. Package Building\n",
    "2. Versioning and Logging\n",
    "3. Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Building ML Pipeline\n",
    "6. Model training\n",
    "7. Model Prediction\n",
    "8. Utility Modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset for training and testing\n",
    "\n",
    "1. Download the train.csv and test.csv files from the [Kaggle Competiton link](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "2. Save train.csv and test.csv files in the datasets folder of your directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning and Logging of deployed model/package\n",
    "\n",
    "Important for:\n",
    "1. Reproducibility\n",
    "Can store information about:\n",
    "    * Input data\n",
    "    * Time frmae in which predicitons were made\n",
    "    \n",
    "2. Clues for Debugging \n",
    "3. Conduct audits to meet Regulatory Requirements on the predictions we are making.\n",
    "\n",
    "\n",
    "\n",
    "**Version file**\n",
    "<br>\n",
    "The Version file contains the specified version in the format [Major.Mino.Patch] eg: 0.1.0.\n",
    "<br>\n",
    "**init.py**\n",
    "<br>\n",
    "To set the version by reading from a file\n",
    "\n",
    "**Config/logging_config.py**\n",
    "\n",
    "1. get_console_handler()<br>\n",
    "   for logging into a console\n",
    "2. get_file_handler()<br>\n",
    "    for logging into a file<br>\n",
    "3. Format to store the metadata which contains datetime , logging function etc\n",
    "4. get_logger()<br>\n",
    "    For calling logger from different modules.\n",
    "\n",
    "Check **data_management.py** file for usage\n",
    "\n",
    "5. errors.py<br>\n",
    "    Custom errors to give us more specific erros at the time of logging.\n",
    "\n",
    "Check **features.py** file for usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and loading package\n",
    "\n",
    "We will be taking top down approach where we will first install the built regression package and then will go in details on how can we build this package\n",
    "\n",
    "1. requirements.txt<br>\n",
    "    List of libraries to be installed\n",
    "2. setup .py<br>\n",
    "    List all the details about the package\n",
    "    \n",
    "**To build package**<br>\n",
    "python packages\\regression_model\\setup.py sdist bdist_wheel\n",
    "\n",
    "\n",
    "sdist - Source Distribution<br>\n",
    "bdist_wheel - Wheel distribution\n",
    "*Note-Modern pip uses wheel distribution*\n",
    "\n",
    "Check the dist folder to find the created package\n",
    "![](images/package.PNG)\n",
    "\n",
    "**To install package locally**<br>\n",
    "pip install -e packages\\regression_model\n",
    "\n",
    "![](images/loading_pckg.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running training pipeline\n",
    "\n",
    "![](images/training.PNG)\n",
    "\n",
    "**Running training pipeline**<br>\n",
    "We can see the role of logger in the output\n",
    "![](images/train_pipeline.PNG)\n",
    "\n",
    "The pickle file is saved under the trained_models folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "**preprocessors.py**<br>\n",
    "    Lists all the preprocessing task involved in this model building exercise.\n",
    "    \n",
    "    * Categorical Imputer\n",
    "    * Numerical Imputer\n",
    "    * Temporal Variable estimator\n",
    "    * RareLabel Categorical Encoder\n",
    "    * Categorical Encoder\n",
    "    * Drop Unnecessary Features\n",
    "**validation.py**<br>\n",
    "    This module validate inputs and it's basically another layer of checking and safety to make sure that any values that come into our model all handled in a way that allows us to continue with prediction.\n",
    "\n",
    "*Check predict module for usage*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "**1. features.py**<br>\n",
    "    List all the feature engineering work.Here we have just a single feature engineering task of log transformation.However this module can be far more complex than this example for eg:\n",
    "    * Accessing a database to pick precalclulated features.\n",
    "    * Third party API call to gather information .eg - Weather\n",
    "    * A separate model to generate features that will be an input feature to our current model.\n",
    "\n",
    "The features can be a very complicated section of your application and it could indeed be imported as a totally separate package with its own versioning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline\n",
    "\n",
    "One of the often reason for ML models to break in production is the reproducibility in offline and online environment.Hence, it is necessary to collate all the preprocessing tasks and create a pipeline that can be leverage both at the time of training and at the time of inference.\n",
    "\n",
    "Current Pipeline does the following tasks:\n",
    "1. Categorical Imputer\n",
    "2. Numerical Imputer\n",
    "3. Temporal Variable\n",
    "4. Rare Label Encoder\n",
    "5. Categorical Encoder\n",
    "6. Log transform\n",
    "7. Drop Features\n",
    "7. MinMax Scalar\n",
    "8. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "**train_pipeline.py**<br>\n",
    "   This module involves training the model leveraging all the modules defined above.\n",
    "   \n",
    "   Major tasks performed in this module:\n",
    "   1. Load Dataset\n",
    "   2. Train-Test Split\n",
    "   3. Trasformation on Target Variable\n",
    "   4. Running Pipeline\n",
    "   5. Saving Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility modules\n",
    "\n",
    "1. **Data Management.py**<br>\n",
    "Lists all the utility functions required in model training.\n",
    "2. **config.py**<br>\n",
    "Configuration file with all the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good practices\n",
    "\n",
    "1. Use version control\n",
    "2. Write tests ! Unit, Integration , Acceptance tests \n",
    "3. Trunk based development and peer reviews\n",
    "4. Understand your system dependencies\n",
    "5. Use CI/CD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST API\n",
    "\n",
    "Representational State Transfer(REST) Application Program Interface(API)\n",
    "\n",
    "Serving our model using API has the following advantages:\n",
    "1. Serve predictions on the fly to multiple clients ( websites,phone,API etc)\n",
    "2. Separate model development from client facing layer\n",
    "3. Combine multiple models at different API endpoints\n",
    "3. Bring Scale ..   by adding more instances of the API application behind any load balancer \n",
    "\n",
    "We will build our API using the Flask microframework.\n",
    "\n",
    "Alternatives to look for:\n",
    "1. Django\n",
    "2. Pyramid\n",
    "3. Bottle\n",
    "4. Tornada\n",
    "5. API Star etc\n",
    "\n",
    "Before going and building the API for our model let us undertsand what an API is???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API \n",
    "\n",
    "An API is an application programming interface. It is a set of rules that allow programs to talk to each other. The developer creates the API on the server and allows the client to talk to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST\n",
    "\n",
    "REST determines how the API looks like.It is a set of rules that developers follow when they create their API.One of these rules states that you should be able to get a piece of data (called a **resource**) when you link to a specific URL.\n",
    "\n",
    "Each URL is called a **request** while the data sent back to you is called a **response**.\n",
    "\n",
    "\n",
    "**JSON (JavaScript Object Notation)** a common format for sending and requesting data through a REST API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUEST\n",
    "\n",
    "request is made up of four things:\n",
    "\n",
    "1. **The endpoint** -The endpoint (or route) is the url you request for.\n",
    "    1. **path** - determines the resource you’re requesting for. Think of it like an automatic answering machine that asks you to press 1 for a service, press 2 for another service, 3 for yet another service and so on.\n",
    "2. **The method** -The method is the type of request you send to the server. You can choose from these five types below:\n",
    "    1. **GET**   - Read a resource on a server\n",
    "    2. **POST**  - Creates a new resource on a server\n",
    "    3. **PUT and PATCH**  - Update a resource on a server\n",
    "    4. **DELETE** - Delete a resource from a server.\n",
    "3. **The headers**    - Headers are used to provide information to both the client and server.eg authentication and providing information about the body content\n",
    "4. **The data (or body)** - The data (sometimes called “body” or “message”) contains information you want to be sent to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our API Package\n",
    "\n",
    "![](images/api_package_content.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requirements.txt\n",
    "\n",
    "**Note- Comment Neural Network and other unrequired packeages\n",
    "\n",
    "Lists the package to build our API Package.\n",
    "\n",
    "Run the requirements file<br>\n",
    "pip install -r packages\\ml_api\\requirements.txt\n",
    "\n",
    "Ignore the neural network package and error for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run.py\n",
    "\n",
    "It is the entry point to start flask.\n",
    "\n",
    "**create_app()** is defined under **api\\app.py** which creates the flask api and the blueprint.Right now the blueprint is creating multiple endpoint which is defined under **api\\controller.py**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## controller.py\n",
    "\n",
    "Lists the different endpoint made in this api.\n",
    "\n",
    "1. Health\n",
    "2. Version\n",
    "    1. Model Version\n",
    "    2. API Version\n",
    "3. Regression Prediction\n",
    "    1. Get the json data\n",
    "    2. Validate the input format of the data\n",
    "    3. Make preictions\n",
    "    4. Send predctions , version , errors as json back to client\n",
    "4. NN Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation.py\n",
    "\n",
    "\n",
    "List the schema details of the data and the validation methods required at the time of running validations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the flask api\n",
    "\n",
    "**To test the running of flask webapp**\n",
    "\n",
    "- cd packages\n",
    "- cd ml_api\n",
    "- set FLASK_APP=run.py\n",
    "- python run.py\n",
    "\n",
    "![](images/run_flask.PNG)\n",
    "Flask app is running at 127.0.0.1:5000\n",
    "\n",
    "Check the **health endpoint** \n",
    "\n",
    "    http://127.0.0.1.5000/health\n",
    "\n",
    "\n",
    "\n",
    "![](images/health_endpoint.PNG)\n",
    "![](images/version.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config.py\n",
    "\n",
    "Similar to the config file for logging format and setup code used in regression package.\n",
    "\n",
    "It has:\n",
    "1. Loggers with right handlers\n",
    "2. Config objects to set particular flask properties.<br>\n",
    "    See usage in app.py<br>\n",
    "    flask_app.config.from_object(config_object)\n",
    "![](images/config.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests\n",
    "\n",
    "1. **tests/conftest.py**\n",
    "\n",
    "Creating test fixtures which can then later be passed in an argument in tests where they return values.\n",
    "\n",
    "They can be used to test any endpoint.\n",
    "\n",
    "2. **tests/test_validation.py**\n",
    "\n",
    "Test file for the validation of validation.py file\n",
    "\n",
    "3. **tests/test_controller.py**\n",
    "\n",
    "Tests different configured endpoints\n",
    "    1. Health endpoint\n",
    "    2. Version endpoint\n",
    "    3. Regression endpoint\n",
    "    4. NN endpoint\n",
    "\n",
    "Lets test our ***health*** endpoint\n",
    "\n",
    "**Note-Comment all other tests for now except health endpoint**<br>\n",
    "tests/test_controller.py\n",
    "![](images/test_controller.PNG)\n",
    "\n",
    "\n",
    "Run - pytest packages/ml_api/tests\n",
    "\n",
    "![](images/tests.PNG)\n",
    "\n",
    "\n",
    "Under test controller you can find :\n",
    "    - test_prediction_endpoint_predictions\n",
    "    Do make a note that all the heavy lifting has been excluded from api and is present in the regression package.So the model package contains all the things to test aswell.In that way we are ruling out a scenario where we update our model but fail to update our test data in the api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASK Crash Course\n",
    "\n",
    "1. @ -Decorators in flask used for defining endpoint or root. Here we are definining a health endpoint and we can access that using http **GET**.\n",
    "\n",
    "![](images/define_endpoint.PNG)\n",
    "\n",
    "2. Blueprint - They are like a code template that record operations to execute when registered on the application.\n",
    "\n",
    "![](images/blueprint.PNG)\n",
    "3. Register the template to the application \n",
    "![](images/register.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuos Integration and Continuos Deployment\n",
    "\n",
    "![](images/CICD.PNG)\n",
    "\n",
    "\n",
    "It talks about automating the stages of development\n",
    "\n",
    "\n",
    "CI/CD pipeline in case of Machine Learning Model Deployment\n",
    "\n",
    "![](images/CICD pipeline.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite -Creating a Github repo\n",
    "\n",
    "Create a git repository \n",
    "Link your local Deployment codes to git repository\n",
    "\n",
    "Steps:\n",
    "1. Goto github and create a repo \n",
    "2. Got to git terminal - > Deploymnet folder\n",
    "3. Make this folder a git repo by typing\n",
    "    - git init\n",
    "    \n",
    "4. Commit the repo\n",
    "    - git add .\n",
    "    - git commit -m \"update\"\n",
    "    \n",
    "4. Setup remote instance\n",
    "    - Copy the https link from github repo\n",
    "    - git remote\n",
    "    - git remote add origin [link]\n",
    "    - git push origin master "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cicle CI\n",
    "\n",
    "We will be building our CI/CD pipeline on CircleCI - a CI/CD platform.\n",
    "\n",
    "Features:\n",
    "1. Hosted Platform  i.e will rely on their servers\n",
    "2. Easy github integration\n",
    "3. Can take up 1 free project\n",
    "\n",
    "Alternatives:\n",
    "1. Jenkins\n",
    "2. Travis CI\n",
    "3. Bamboo\n",
    "4. Gitlab CI\n",
    "5. Team City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Circle CI\n",
    "\n",
    "1. Login to Cicle CI using github account.\n",
    "2. Add a project \"Deployment\" from your github repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "1. [Git CheatSheet](https://www.atlassian.com/git/tutorials/atlassian-git-cheatsheet)\n",
    "2. [Git course](https://www.pluralsight.com/courses/code-school-git-real)\n",
    "3. [Working with folks](https://stackoverflow.com/questions/25545613/how-can-i-push-to-my-fork-from-a-clone-of-the-original-repo)\n",
    "4. [Testing](https://landing.google.com/sre/sre-book/chapters/testing-reliability/)\n",
    "5. [Trunk based Development](https://trunkbaseddevelopment.com/)\n",
    "6. Fluent Python\n",
    "7. The Devops Handbook<BR>\n",
    "**PACKAGING**    \n",
    "8. [Python Packaging](https://packaging.python.org/)\n",
    "9. [Python Versioning](https://packaging.python.org/guides/single-sourcing-package-version/)\n",
    "10. [ Python Logging](https://docs.python.org/3/library/logging.html)\n",
    "9. [Python packaging and PyPI](https://www.youtube.com/watch?v=na0hQI5Ep5E)\n",
    "10. [Setuptools documentation](https://setuptools.readthedocs.io/en/latest/)\n",
    "11. [Wheel Documentation](https://wheel.readthedocs.io/en/stable/)\n",
    "12. [Pytest Documentation](https://docs.pytest.org/en/latest/)<BR>\n",
    "**REST API**\n",
    "13. [REST API Principles](https://restfulapi.net/rest-architectural-constraints/)\n",
    "14. [REST API Walkthrough](https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/)\n",
    "15. [Flask Tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)\n",
    "16. [Web Frameworks](https://github.com/vinta/awesome-python#web-frameworks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
